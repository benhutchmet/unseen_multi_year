{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import dictionaries as dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters\n",
    "# ----------------------\n",
    "model_variable = \"sfcWind\"\n",
    "obs_variable = \"si10\"\n",
    "model = \"HadGEM3-GC31-MM\"\n",
    "experiment = \"dcppA-hindcast\"\n",
    "start_year = 1960\n",
    "end_year = 2018\n",
    "avg_period = 2 # in years\n",
    "grid = dicts.north_sea_kay\n",
    "\n",
    "# Set up the first file\n",
    "# ----------------------\n",
    "first_year = start_year\n",
    "first_member = \"r1i1p1f2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lon and lat bounds\n",
    "lon1, lon2, lat1, lat2 = grid[\"lon1\"], grid[\"lon2\"], grid[\"lat1\"], grid[\"lat2\"]\n",
    "\n",
    "# import the csv\n",
    "df = pd.read_csv(\"paths/paths_20240117T122513.csv\")\n",
    "\n",
    "# Extract the path for the model\n",
    "# Extract the path for the model and experiment and variable\n",
    "model_path = df.loc[(df['model'] == model) & (df['experiment'] == experiment) & (df['variable'] == model_variable), 'path'].values[0]\n",
    "\n",
    "# List the files in the directory\n",
    "files = glob.glob(model_path + \"/*.nc\")\n",
    "\n",
    "# # print the files\n",
    "# print(files)\n",
    "\n",
    "# # Find the file containing the first year and member\n",
    "first_file = [f for f in files if f\"s{first_year}\" in f and f\"{first_member}\" in f][0]\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset(first_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the file\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we want to concatenate all ensemble members for the first year\n",
    "# --------------------------------------------------------------------\n",
    "# find all the ensemble members for the first year\n",
    "first_files = [f for f in files if f\"s{first_year}\" in f]\n",
    "\n",
    "# print the first files\n",
    "print(first_files)\n",
    "\n",
    "# Open the first files\n",
    "ds = xr.open_mfdataset(first_files, concat_dim=\"ensemble_member\", combine=\"nested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the file\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the source id\n",
    "print(ds.attrs[\"source_id\"])\n",
    "\n",
    "# Print the variant label\n",
    "print(ds.attrs[\"variant_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to extract the data for a single ensemble member\n",
    "# for the first 10 years\n",
    "# -----------------------------------------------------------\n",
    "# Create a list to append the data\n",
    "data = []\n",
    "\n",
    "\n",
    "# Loop over the first 10 years\n",
    "for year in np.arange(start_year, 1970 + 1):\n",
    "    # find all the ensemble members for the first year\n",
    "    first_files = [f for f in files if f\"s{year}\" in f and f\"{first_member}\" in f][0]\n",
    "\n",
    "    # Append the data\n",
    "    data.append(first_files)\n",
    "\n",
    "# print the data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to define a function to preprocess the data\n",
    "# --------------------------------------------------\n",
    "def preprocess(ds):\n",
    "    \"\"\"\n",
    "    Preprocess the data\n",
    "    \"\"\"\n",
    "    # Create a new dimension for the ensemble member\n",
    "    ds = ds.expand_dims(\"ensemble_member\")\n",
    "\n",
    "    # Set the ensemble_member\n",
    "    ds[\"ensemble_member\"] = [ds.attrs[\"variant_label\"]]\n",
    "\n",
    "    # Take the mean over the first year of the data\n",
    "    # First extract the first year\n",
    "    first_year = ds.time.dt.year[0].values\n",
    "\n",
    "    # Take the mean over the first year\n",
    "    ds = ds.sel(time=slice(f\"{first_year}-12-01\", f\"{first_year + 1}-11-30\")).mean(\"time\")\n",
    "\n",
    "    # Revert time to the centre of the mean period\n",
    "    ds[\"time\"] = pd.to_datetime(f\"{first_year + 1}-06-01\")\n",
    "\n",
    "    # Return the dataset\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an empty list to append the data\n",
    "dss = []\n",
    "\n",
    "# Variant label\n",
    "variant_labels = []\n",
    "\n",
    "# Extract the unique variant labels\n",
    "for file in files:\n",
    "    # Open the file\n",
    "    ds = xr.open_dataset(file)\n",
    "\n",
    "    # Extract the variant label\n",
    "    variant_label = ds.attrs[\"variant_label\"]\n",
    "\n",
    "    # If the variant label is not in the list, append the data\n",
    "    if variant_label not in variant_labels:\n",
    "        variant_labels.append(variant_label)\n",
    "        \n",
    "print(variant_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that the variant labels are unique\n",
    "assert len(variant_labels) == len(set(variant_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the path for the model\n",
    "# Extract the path for the model and experiment and variable\n",
    "model_path = df.loc[(df['model'] == model) & (df['experiment'] == experiment) & (df['variable'] == model_variable), 'path'].values[0]\n",
    "\n",
    "for v_lab in tqdm(variant_labels):\n",
    "    # Set up the path to the data\n",
    "    model_path_mem = f\"{model_path}/{model_variable}_Amon_{model}_{experiment}_s????-{v_lab}_g?_*.nc\"\n",
    "\n",
    "    # # print the model path\n",
    "    # print(model_path_mem)\n",
    "\n",
    "    # Print the variant label\n",
    "    print(v_lab)\n",
    "\n",
    "    # Open the files\n",
    "    ds = xr.open_mfdataset(model_path_mem,\n",
    "                            preprocess=preprocess,\n",
    "                            combine=\"nested\",\n",
    "                            concat_dim=\"time\",\n",
    "                            join=\"override\",\n",
    "                            coords=\"minimal\",\n",
    "                            parallel=True)\n",
    "\n",
    "    # Append the data\n",
    "    dss.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the data along the ensemble member dimension\n",
    "ds = xr.concat(dss, dim=\"ensemble_member\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sfcWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the wind speed climatology for the north sea\n",
    "# ------------------------------------------------------\n",
    "ns_lat1, ns_lat2, ns_lon1, ns_lon2 = dicts.north_sea_kay[\"lat1\"], dicts.north_sea_kay[\"lat2\"], dicts.north_sea_kay[\"lon1\"], dicts.north_sea_kay[\"lon2\"]\n",
    "\n",
    "# Extract the data for the north sea\n",
    "ds_ns = ds.sel(lat=slice(ns_lat1, ns_lat2), lon=slice(ns_lon1, ns_lon2)).mean([\"lat\", \"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values\n",
    "print(ds_ns.sfcWind.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the wind speed climatology and remove it from the data\n",
    "# --------------------------------------------------------------\n",
    "# Take the mean over the ensemble members and time\n",
    "ds_ns_clim = ds_ns.mean([\"ensemble_member\", \"time\"])\n",
    "\n",
    "# Calculate the anomaly\n",
    "ds_ns_anom = ds_ns - ds_ns_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the anomaly\n",
    "ds_ns_anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the values\n",
    "ds_ns_anom.sfcWind.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all files by init_time and ensemble_member\n",
    "# -------------------------------------------------\n",
    "data_combine_all = xr.open_mfdataset(files, preprocess=preprocess, combine=\"nested\", concat_dim=\"ensemble_member\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfcWind_data = data_combine_all.sfcWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(sfcWind_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfcWind_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_combine_all.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_merged=xr.Dataset()\n",
    "\n",
    "for file in data:\n",
    "\n",
    "        da_merged = xr.merge([da_merged,xr.open_mfdataset(file)],compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_merged.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data for init_time in 1970\n",
    "# --------------------------------------\n",
    "data_1970 = data_combine.sel(init_time=\"1970\")\n",
    "\n",
    "# Look at the data\n",
    "data_1970.time.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
