{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process UNSEEN ###\n",
    "\n",
    "But in notebook form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/benhutch/.conda/envs/bens-conda-env2/lib/python3.11/site-packages/pyproj/network.py:59: UserWarning: pyproj unable to set PROJ database path.\n",
      "  _set_context_ca_bundle_path(ca_bundle_path)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "\n",
    "# Local imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shapely.geometry\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import iris\n",
    "\n",
    "# Specific imports\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load my specific functions\n",
    "sys.path.append(\"/home/users/benhutch/unseen_functions\")\n",
    "import functions as funcs\n",
    "import bias_adjust as ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded variables\n",
    "model = \"HadGEM3-GC31-MM\"\n",
    "experiment = \"dcppA-hindcast\"\n",
    "freq = \"Amon\" # go back to using monthly data\n",
    "\n",
    "# Set up the arguments\n",
    "variable = \"tas\"\n",
    "country = \"United Kingdom\"\n",
    "season = \"ONDJFM\"\n",
    "first_year = 1960\n",
    "last_year = 2018\n",
    "model_fcst_year = 1\n",
    "lead_year = \"1-10\"\n",
    "detrend = True # True for temperature, false for wind speeds\n",
    "bias_correct = \"None\" # No bias correction for tas months\n",
    "percentile = 10\n",
    "\n",
    "# Save directory\n",
    "save_dir = \"/gws/nopw/j04/canari/users/benhutch/plots/unseen\"\n",
    "\n",
    "# list of valid bias corrections\n",
    "valid_bias_corrections = [\n",
    "    \"None\",\n",
    "    \"linear_scaling\",\n",
    "    \"variance_scaling\",\n",
    "    \"quantile_mapping\",\n",
    "    \"quantile_delta_mapping\",\n",
    "    \"scaled_distribution_mapping\",\n",
    "]\n",
    "\n",
    "# Set up the output directory for the dfs\n",
    "output_dir_dfs = \"/gws/nopw/j04/canari/users/benhutch/unseen/saved_dfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the bias correction is not in the valid bias corrections\n",
    "if bias_correct not in valid_bias_corrections:\n",
    "    raise ValueError(f\"Bias correction {bias_correct} not recognised\")\n",
    "\n",
    "# set up the obs variable depending on the variable\n",
    "if variable == \"tas\":\n",
    "    obs_var = \"t2m\"\n",
    "elif variable == \"sfcWind\":\n",
    "    obs_var = \"si10\"\n",
    "else:\n",
    "    raise ValueError(\"Variable not recognised\")\n",
    "\n",
    "# Set up the months depending on the season\n",
    "if season == \"DJF\":\n",
    "    months = [12, 1, 2]\n",
    "elif season == \"NDJ\":\n",
    "    months = [11, 12, 1]\n",
    "elif season == \"OND\":\n",
    "    months = [10, 11, 12]\n",
    "elif season == \"JFM\":\n",
    "    months = [1, 2, 3]\n",
    "elif season == \"MAM\":\n",
    "    months = [3, 4, 5]\n",
    "elif season == \"JJA\":\n",
    "    months = [6, 7, 8]\n",
    "elif season == \"SON\":\n",
    "    months = [9, 10, 11]\n",
    "elif season == \"ONDJFM\":\n",
    "    months = [10, 11, 12, 1, 2, 3]\n",
    "elif season == \"NDJFM\":\n",
    "    months = [11, 12, 1, 2, 3]\n",
    "else:\n",
    "    raise ValueError(\"Season not recognised\")\n",
    "\n",
    "# Depending on the model forecast year\n",
    "# set the leads to extract from the model\n",
    "if model_fcst_year == 0 and season == \"NDJFM\":\n",
    "    lead_months = [1, 2, 3, 4, 5]\n",
    "elif model_fcst_year == 1 and season == \"ONDJFM\":\n",
    "    lead_months = [12, 13, 14, 15, 16, 17]\n",
    "elif model_fcst_year == 1 and season in [\"OND\", \"NDJ\", \"DJF\", \"JFM\"]:\n",
    "    lead_months = [12, 13, 14, 15, 16, 17] # include all then subset later\n",
    "else:\n",
    "    raise ValueError(\"Model forecast year and season not recognised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the name for the obs df\n",
    "obs_df_name = f\"ERA5_obs_{variable}_{country}_{season}_{first_year}_{last_year}.csv\"\n",
    "\n",
    "# Set up the name for the model df\n",
    "model_df_name = f\"{model}_{variable}_{country}_{season}_{first_year}_{last_year}_{experiment}_{freq}.csv\"\n",
    "\n",
    "# form the full paths for the dfs\n",
    "obs_df_path = os.path.join(output_dir_dfs, obs_df_name)\n",
    "model_df_path = os.path.join(output_dir_dfs, model_df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the observed and model dfs\n",
      "CPU times: user 18 ms, sys: 4.09 ms, total: 22 ms\n",
      "Wall time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# if the obs df exists and the model df exists\n",
    "if os.path.exists(obs_df_path) and os.path.exists(model_df_path):\n",
    "    print(\"Loading the observed and model dfs\")\n",
    "\n",
    "    # load the dfs\n",
    "    obs_df = pd.read_csv(obs_df_path)\n",
    "    model_df = pd.read_csv(model_df_path)\n",
    "\n",
    "    # print(\"Loaded the dfs\")\n",
    "    # print(\"----------------\")\n",
    "    # print(\"Script complete\")\n",
    "else:\n",
    "    print(\"Creating the observed and model dfs\")\n",
    "    # Set up the path to the ERA5 data\n",
    "    # if the variable is tas\n",
    "    if variable == \"tas\":\n",
    "        # already regridded!\n",
    "        obs_path = (\n",
    "            \"/gws/nopw/j04/canari/users/benhutch/ERA5/t2m_ERA5_regrid_HadGEM.nc\"\n",
    "        )\n",
    "    # if the variable is sfcWind\n",
    "    elif variable == \"sfcWind\":\n",
    "        # needs regridding\n",
    "        obs_path = \"/gws/nopw/j04/canari/users/benhutch/ERA5/surface_wind_ERA5.nc\"\n",
    "    else:\n",
    "        raise ValueError(\"Variable not recognised\")\n",
    "\n",
    "    # Load the model ensemble\n",
    "    model_ds = funcs.load_model_data_xarray(\n",
    "        model_variable=variable,\n",
    "        model=model,\n",
    "        experiment=experiment,\n",
    "        start_year=first_year,\n",
    "        end_year=last_year,\n",
    "        first_fcst_year=int(first_year) + 1,\n",
    "        last_fcst_year=int(first_year) + 2,\n",
    "        months=months,\n",
    "        frequency=freq,\n",
    "        parallel=False,\n",
    "    )\n",
    "\n",
    "    # print that we have loaded the model data\n",
    "    print(\"Loaded the model data\")\n",
    "\n",
    "    # # Get the size of the model data in bytes\n",
    "    # size_in_bytes = model_ds[variable].size * model_ds[variable].dtype.itemsize\n",
    "\n",
    "    # # Convert bytes to gigabytes\n",
    "    # size_in_gb = size_in_bytes / (1024 ** 3)\n",
    "\n",
    "    # # Print the size\n",
    "    # print(f\"Model data size: {size_in_gb} GB\")\n",
    "\n",
    "    # Modify member coordiante before conbersion to iris\n",
    "    model_ds[\"member\"] = model_ds[\"member\"].str[1:-6].astype(int)\n",
    "\n",
    "    # convert to an iris cube\n",
    "    model_cube = model_ds[variable].squeeze().to_iris()\n",
    "\n",
    "    # Load the observed data\n",
    "    obs_ds = xr.open_mfdataset(\n",
    "        obs_path,\n",
    "        combine=\"by_coords\",\n",
    "        parallel=False,\n",
    "        engine=\"netcdf4\",\n",
    "    )\n",
    "\n",
    "    # Restrict the time to the region we are interested in\n",
    "    obs_ds = obs_ds.sel(\n",
    "        time=slice(\n",
    "            f\"{int(first_year)}-{months[0]}-01\",\n",
    "            f\"{int(last_year) + 1}-{months[-1]}-31\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # If expver is present in the observations\n",
    "    if \"expver\" in obs_ds.coords:\n",
    "        # Combine the first two expver variables\n",
    "        obs_ds = obs_ds.sel(expver=1).combine_first(obs_ds.sel(expver=5))\n",
    "\n",
    "    # # Get the size of the observed data in bytes\n",
    "    # size_in_bytes = obs_ds[obs_var].size * obs_ds[obs_var].dtype.itemsize\n",
    "\n",
    "    # # Convert bytes to gigabytes\n",
    "    # size_in_gb = size_in_bytes / (1024 ** 3)\n",
    "\n",
    "    # # Print the size\n",
    "    # print(f\"Observed data size: {size_in_gb} GB\")\n",
    "\n",
    "    # convert to an iris cube\n",
    "    obs_cube = obs_ds[obs_var].squeeze().to_iris()\n",
    "\n",
    "    # if the lats and lons are not the same\n",
    "    if (\n",
    "        not model_cube.coord(\"latitude\").shape == obs_cube.coord(\"latitude\").shape\n",
    "        or not model_cube.coord(\"longitude\").shape\n",
    "        == obs_cube.coord(\"longitude\").shape\n",
    "    ):\n",
    "        print(\"Regridding model data\")\n",
    "        # regrid the obs cube to the model cube\n",
    "        obs_cube = obs_cube.regrid(model_cube, iris.analysis.Linear())\n",
    "\n",
    "    # make sure the cubes are correct in -180 to 180 lons\n",
    "    obs_cube = obs_cube.intersection(longitude=(-180, 180))\n",
    "    model_cube = model_cube.intersection(longitude=(-180, 180))\n",
    "\n",
    "    # create the mask\n",
    "    MASK_MATRIX = funcs.create_masked_matrix(\n",
    "        country=country,\n",
    "        cube=model_cube,\n",
    "    )\n",
    "\n",
    "    # print the shape of the mask matrix\n",
    "    print(f\"Mask matrix shape: {MASK_MATRIX.shape}\")\n",
    "\n",
    "    # print the sum of the mask matrix\n",
    "    print(f\"Mask matrix sum: {np.sum(MASK_MATRIX)}\")\n",
    "\n",
    "    # Apply the mask to the observed data\n",
    "    obs_values = obs_cube.data * MASK_MATRIX\n",
    "    model_values = model_cube.data * MASK_MATRIX\n",
    "\n",
    "    # Where there are zeros in the mask we want to set these to Nans\n",
    "    obs_values_masked = np.where(MASK_MATRIX == 0, np.nan, obs_values)\n",
    "    model_values_masked = np.where(MASK_MATRIX == 0, np.nan, model_values)\n",
    "\n",
    "    # Take the Nanmean of the data\n",
    "    obs_values = np.nanmean(obs_values_masked, axis=(1, 2))\n",
    "    model_values = np.nanmean(model_values_masked, axis=(3, 4))\n",
    "\n",
    "    # Set up the ref time for the observations\n",
    "    ref_time_obs = datetime(1900, 1, 1)\n",
    "\n",
    "    # Extract the obs time points\n",
    "    obs_time_points = obs_cube.coord(\"time\").points\n",
    "\n",
    "    # convert to obs datetimes\n",
    "    obs_datetimes = [\n",
    "        ref_time_obs + timedelta(hours=int(tp)) for tp in obs_time_points\n",
    "    ]\n",
    "\n",
    "    # Set up a dataframe for the observations\n",
    "    obs_df = pd.DataFrame(\n",
    "        {\n",
    "            \"time\": obs_datetimes,\n",
    "            \"obs\": obs_values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # set up an empty df for the model data\n",
    "    model_df = pd.DataFrame()\n",
    "\n",
    "    # extract the init, member and lead time points\n",
    "    init_years = model_cube.coord(\"init\").points\n",
    "    members = model_cube.coord(\"member\").points\n",
    "    lead_times = model_cube.coord(\"lead\").points\n",
    "\n",
    "    # loop through the inits, members and leadtimes\n",
    "    for i, init_year in enumerate(init_years):\n",
    "        for m, member in enumerate(members):\n",
    "            for l, lead_time in enumerate(lead_times):\n",
    "                # get the model data\n",
    "                model_data = model_values[i, m, l]\n",
    "\n",
    "                # set up the model df this\n",
    "                model_df_this = pd.DataFrame(\n",
    "                    {\n",
    "                        \"init_year\": [init_year],\n",
    "                        \"member\": [member],\n",
    "                        \"lead\": [lead_time],\n",
    "                        \"data\": [model_data],\n",
    "                    },\n",
    "                )\n",
    "\n",
    "                # concat to the model df\n",
    "                model_df = pd.concat([model_df, model_df_this])\n",
    "\n",
    "    # print the head of the obs df\n",
    "    print(obs_df.head())\n",
    "\n",
    "    # print the head of the model df\n",
    "    print(model_df.head())\n",
    "\n",
    "    # save the dfs\n",
    "    if not os.path.exists(output_dir_dfs):\n",
    "        os.makedirs(output_dir_dfs)\n",
    "\n",
    "    # save the obs df\n",
    "    if not os.path.exists(obs_df_path):\n",
    "        print(\"Saving the observed df\")\n",
    "        obs_df.to_csv(obs_df_path, index=False)\n",
    "\n",
    "    # save the model df\n",
    "    if not os.path.exists(model_df_path):\n",
    "        print(\"Saving the model df\")\n",
    "        model_df.to_csv(model_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   obs\n",
      "time                  \n",
      "1960-10-01  282.668868\n",
      "1960-11-01  279.559365\n",
      "1960-12-01  276.477476\n",
      "1961-01-01  275.904981\n",
      "1961-02-01  279.151625\n"
     ]
    }
   ],
   "source": [
    "# constrain the obs df to only months 10, 11, 12, 1, 2, 3\n",
    "# esnure that the time is a datetime\n",
    "obs_df[\"time\"] = pd.to_datetime(obs_df[\"time\"])\n",
    "\n",
    "# set the time as the index for the obs df\n",
    "obs_df.set_index(\"time\", inplace=True)\n",
    "\n",
    "# # remove the name of the index\n",
    "# obs_df.index.name = None\n",
    "\n",
    "# print the head of the obs df\n",
    "print(obs_df.head())\n",
    "\n",
    "# constrain to the months\n",
    "obs_df = obs_df[obs_df.index.month.isin(months)]\n",
    "\n",
    "# NOTE: Not taking ONDJFM averages\n",
    "# if months contains 12, 1 in sequence\n",
    "# if 12 in months and 1 in months:\n",
    "#     # shift back by months and take the annual mean\n",
    "#     obs_df = obs_df.shift(-int(months[-1])).resample(\"A\").mean()\n",
    "\n",
    "# if there are any Nans in the obs df, drop them\n",
    "obs_df.dropna(inplace=True)\n",
    "\n",
    "# set up time as a column\n",
    "obs_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leads to extract: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# create a new model df for subsetting to first ONDJFM\n",
    "model_df_ondjfm = pd.DataFrame()\n",
    "\n",
    "# turn leads into a list of ints\n",
    "if lead_year != \"9999\":\n",
    "    if \"-\" in lead_year:\n",
    "        leads = list(\n",
    "            range(\n",
    "                int(lead_year.split(\"-\")[0]),\n",
    "                int(lead_year.split(\"-\")[1]) + 1,\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        leads = [int(lead_year)]\n",
    "\n",
    "    # print the leads to extract\n",
    "    print(f\"Leads to extract: {leads}\")\n",
    "elif lead_year == \"9999\":\n",
    "    # Set up the leads to extract list range 1-10\n",
    "    leads = list(range(1, 11))\n",
    "else:\n",
    "    raise ValueError(\"Lead year not recognised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the unique init years and members in model_df\n",
    "for init_year in model_df[\"init_year\"].unique():\n",
    "    for member in model_df[\"member\"].unique():\n",
    "        for l in leads:\n",
    "            # extract the model data\n",
    "            model_data = model_df[\n",
    "                (model_df[\"init_year\"] == init_year)\n",
    "                & (model_df[\"member\"] == member)\n",
    "            ]\n",
    "\n",
    "            # create the list of lead months to extract\n",
    "            lead_months_year_base = [l * lead_months[0] for lm in lead_months]\n",
    "\n",
    "            # # print the lead months year base\n",
    "            # print(\"lead months year base:\", lead_months_year_base)\n",
    "\n",
    "            # create the list of lead months to extract\n",
    "            for i in range(len(lead_months_year_base)):\n",
    "                lead_months_year_base[i] = lead_months_year_base[i] + i\n",
    "\n",
    "            # # print the lead months year base\n",
    "            # print(\"lead months year base:\", lead_months_year_base)\n",
    "\n",
    "            # # subset to lead values [12, 13, 14, 15, 16, 17] and take the mean\n",
    "            # # first complete ONDJFM season\n",
    "            # # FIXME: Hardcoded for now\n",
    "            # model_data = model_data[model_data[\"lead\"].isin(lead_months_year_base)]\n",
    "\n",
    "            # mean_data = model_data[\"data\"].mean()\n",
    "                \n",
    "            # # print lead months year base\n",
    "            # print(\"lead months year base:\", lead_months_year_base)\n",
    "\n",
    "            # loop over the lead months\n",
    "            for lm in lead_months_year_base:\n",
    "                # subset to the lead month\n",
    "                mean_data = model_data[model_data[\"lead\"] == lm].mean()[\"data\"]\n",
    "\n",
    "                # create a dataframe this\n",
    "                model_data_this = pd.DataFrame(\n",
    "                    {\n",
    "                        \"init_year\": [init_year],\n",
    "                        \"member\": [member],\n",
    "                        \"lead\": [lm],\n",
    "                        \"data\": [mean_data],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                model_df_ondjfm = pd.concat([model_df_ondjfm, model_data_this])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detrending the data, no bias correction\n",
      "The mean slope is 0.03007167605425015\n",
      "The 2.5th percentile of the slopes is 0.004921807033942651\n",
      "The 97.5th percentile of the slopes is 0.05187120580376486\n",
      "The slope of the observations is 0.02825383544191476\n",
      "The trend line obs is [277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 277.31452504 277.31452504\n",
      " 277.31452504 277.31452504 277.31452504 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226 279.05868226\n",
      " 279.05868226 279.05868226 279.05868226 279.05868226]\n",
      "The trend line model is [277.31452504 277.31452504 277.31452504 ... 279.05868226 279.05868226\n",
      " 279.05868226]\n",
      "The trend final is 279.05868225511455\n",
      "The trend final obs is 279.08875393116875\n",
      "The model_val_name is data\n",
      "The obs_val_name is obs\n",
      "The mean of the model data is 279.05868225511455\n",
      "The mean of the obs data is 279.1439487587466\n"
     ]
    }
   ],
   "source": [
    "# if the detrend is True\n",
    "if detrend and bias_correct == \"None\":\n",
    "    print(\"Detrending the data, no bias correction\")\n",
    "\n",
    "    # apply the function to detrend the data\n",
    "    obs_df, model_df_ondjfm = funcs.apply_detrend(\n",
    "        obs_df=obs_df,\n",
    "        model_df=model_df_ondjfm,\n",
    "        obs_val_name=\"obs\",\n",
    "        model_val_name=\"data\",\n",
    "        obs_time_name=\"time\",\n",
    "        model_time_name=\"init_year\",\n",
    "        model_member_name=\"member\",\n",
    "        model_lead_name=\"lead\",\n",
    "    )\n",
    "\n",
    "    # Set up the name for the obs val name\n",
    "    obs_val_name = \"obs_dt\"\n",
    "    model_val_name = \"data_dt\"\n",
    "elif bias_correct != \"None\" and not detrend:\n",
    "    print(\"Bias correcting the data, no detrending\")\n",
    "\n",
    "    # if the bias correction is linear_scaling\n",
    "    if bias_correct == \"linear_scaling\":\n",
    "        # apply the function to bias correct the data\n",
    "        model_df_ondjfm = funcs.bc_linear_scaling(\n",
    "            obs_df=obs_df,\n",
    "            model_df=model_df_ondjfm,\n",
    "            obs_val_name=\"obs\",\n",
    "            model_val_name=\"data\",\n",
    "        )\n",
    "    elif bias_correct == \"variance_scaling\":\n",
    "        # apply the function to bias correct the data\n",
    "        model_df_ondjfm = funcs.bc_variance_scaling(\n",
    "            obs_df=obs_df,\n",
    "            model_df=model_df_ondjfm,\n",
    "            obs_val_name=\"obs\",\n",
    "            model_val_name=\"data\",\n",
    "        )\n",
    "    elif bias_correct == \"quantile_mapping\":\n",
    "        # Use James functions to correct the model data\n",
    "        qm_adjustment = ba.QMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_bc\"] = qm_adjustment.correct()\n",
    "    elif bias_correct == \"quantile_delta_mapping\":\n",
    "        # Use James functions to correct the model data\n",
    "        qdm_adjustment = ba.QDMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_bc_qdm\"] = qdm_adjustment.correct()\n",
    "\n",
    "        # compare to the quantile mapping adjustment\n",
    "        qm_adjustment = ba.QMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_bc_qm\"] = qm_adjustment.correct()\n",
    "\n",
    "        # take the difference between the two columns\n",
    "        model_df_ondjfm[\"data_bc_diff\"] = model_df_ondjfm[\"data_bc_qm\"] - model_df_ondjfm[\"data_bc_qdm\"]\n",
    "\n",
    "        # print the head of the model df\n",
    "        print(model_df_ondjfm.head())\n",
    "\n",
    "        # print the tail of the model df\n",
    "        print(model_df_ondjfm.tail())\n",
    "    elif bias_correct == \"scaled_distribution_mapping\":\n",
    "        print(\"Applying scaled distribution mapping\")\n",
    "\n",
    "        sdm_adjustment = ba.SDMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_bc\"] = sdm_adjustment.correct()\n",
    "    else:\n",
    "        print(f\"Bias correction method {bias_correct} not recognised\")\n",
    "\n",
    "    # Set up the name for the obs val name\n",
    "    obs_val_name = \"obs\"\n",
    "    model_val_name = \"data_bc\"\n",
    "\n",
    "    # print the mean bias\n",
    "    print(\n",
    "        \"Mean bias:\",\n",
    "        np.mean(model_df_ondjfm[model_val_name]) - np.mean(obs_df[obs_val_name]),\n",
    "    )\n",
    "\n",
    "    # print the spread bias\n",
    "    print(\n",
    "        \"Spread bias:\",\n",
    "        np.std(model_df_ondjfm[model_val_name]) - np.std(obs_df[obs_val_name]),\n",
    "    )\n",
    "\n",
    "elif bias_correct != \"None\" and detrend:\n",
    "    print(\"Bias correcting the data and detrending\")\n",
    "\n",
    "    # apply the function to detrend the data\n",
    "    obs_df, model_df_ondjfm = funcs.apply_detrend(\n",
    "        obs_df=obs_df,\n",
    "        model_df=model_df_ondjfm,\n",
    "        obs_val_name=\"obs\",\n",
    "        model_val_name=\"data\",\n",
    "        obs_time_name=\"time\",\n",
    "        model_time_name=\"init_year\",\n",
    "        model_member_name=\"member\",\n",
    "        model_lead_name=\"lead\",\n",
    "    )\n",
    "\n",
    "    # # print the mean of the model data\n",
    "    # print(\"Model data mean before bias correction:\", np.mean(model_df_ondjfm[\"data_dt\"]))\n",
    "\n",
    "    # # print the spread of the model data\n",
    "    # print(\"Model data spread before bias correction:\", np.std(model_df_ondjfm[\"data_dt\"]))\n",
    "\n",
    "    if bias_correct == \"linear_scaling\":\n",
    "        # apply the function to bias correct the data\n",
    "        model_df_ondjfm = funcs.bc_linear_scaling(\n",
    "            obs_df=obs_df,\n",
    "            model_df=model_df_ondjfm,\n",
    "            obs_val_name=\"obs_dt\",\n",
    "            model_val_name=\"data_dt\",\n",
    "        )\n",
    "    elif bias_correct == \"variance_scaling\":\n",
    "        # apply the function to bias correct the data\n",
    "        model_df_ondjfm = funcs.bc_variance_scaling(\n",
    "            obs_df=obs_df,\n",
    "            model_df=model_df_ondjfm,\n",
    "            obs_val_name=\"obs_dt\",\n",
    "            model_val_name=\"data_dt\",\n",
    "        )\n",
    "    elif bias_correct == \"quantile_mapping\":\n",
    "        # use James' functions to correct the model data\n",
    "        qm_adjustment = ba.QMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data_dt\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_dt_bc\"] = qm_adjustment.correct()\n",
    "    elif bias_correct == \"quantile_delta_mapping\":\n",
    "        # Use James functions to correct the model data\n",
    "        qdm_adjustment = ba.QDMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data_dt\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_dt_bc\"] = qdm_adjustment.correct()\n",
    "    elif bias_correct == \"scaled_distribution_mapping\":\n",
    "        print(\"Applying scaled distribution mapping\")\n",
    "\n",
    "        sdm_adjustment = ba.SDMBiasAdjust(\n",
    "            obs_data = obs_df[\"obs\"],\n",
    "            mod_data = model_df_ondjfm[\"data_dt\"],\n",
    "        )\n",
    "\n",
    "        # assign the corrected data to the model df\n",
    "        model_df_ondjfm[\"data_dt_bc\"] = sdm_adjustment.correct()\n",
    "    else:\n",
    "        print(f\"Bias correction method {bias_correct} not recognised\")\n",
    "        sys.exit()\n",
    "\n",
    "    # # print the mean of the model data\n",
    "    # print(\"Model data mean after bias correction:\", np.mean(model_df_ondjfm[\"data_dt_bc\"]))\n",
    "\n",
    "    # # print the spread of the model data\n",
    "    # print(\"Model data spread after bias correction:\", np.std(model_df_ondjfm[\"data_dt_bc\"]))\n",
    "\n",
    "    # # print the observed mean\n",
    "    # print(\"Observed data mean before bias correction:\", np.mean(obs_df[\"obs_dt\"]))\n",
    "\n",
    "    # # print the spread of the observed data\n",
    "    # print(\"Observed data spread before bias correction:\", np.std(obs_df[\"obs_dt\"]))\n",
    "\n",
    "    # sys.exit()\n",
    "\n",
    "    # Set up the name for the obs val name\n",
    "    obs_val_name = \"obs_dt\"\n",
    "    model_val_name = \"data_dt_bc\"\n",
    "\n",
    "else:\n",
    "    obs_val_name = \"obs\"\n",
    "    model_val_name = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Obs val name: obs_dt\n",
      "Model val name: data_dt\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# print the obs val name being used\n",
    "print(\"----------------\")\n",
    "print(f\"Obs val name: {obs_val_name}\")\n",
    "print(f\"Model val name: {model_val_name}\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          10        11        12        1         2         3 \n",
      "10  1.000000  0.182450  0.053183  0.049317 -0.109607  0.008447\n",
      "11  0.182450  1.000000  0.112174  0.092839  0.189726  0.014877\n",
      "12  0.053183  0.112174  1.000000  0.316295  0.069747  0.083370\n",
      "1   0.049317  0.092839  0.316295  1.000000  0.461421  0.253755\n",
      "2  -0.109607  0.189726  0.069747  0.461421  1.000000  0.479750\n",
      "3   0.008447  0.014877  0.083370  0.253755  0.479750  1.000000\n"
     ]
    }
   ],
   "source": [
    "# test the function for quantifying autocorrelation\n",
    "funcs.calc_autocorr_obs(\n",
    "    obs_df=obs_df,\n",
    "    obs_val_name=obs_val_name,\n",
    "    months=months,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bens-conda-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
